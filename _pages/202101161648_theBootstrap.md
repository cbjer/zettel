---
title: The Bootrap
permalink: /zettel/202101161648_theBootstrap
layout: page
tags: estimation

---
# The Bootrap

The Bootstrap method is used to estimate statistical properties of a distribution without having to sample new data points from the distribution. The 
general idea is to take our 1 data sample and to sample with replacement from this data sample, calculating a [statistical estimator](202012241539_estimatorDefinition) 
on each sample. Combining these estimates allows us to calculate statistics on the estimator, for example a [confidence interval](202111060012_ConfidenceInterval).

For example:
- We have a total dataset $\mathbf{Z} = (z_1, \ldots, z_N)$
- Say we want to estimate what is the variance of a prediction at some point $z_0$.
- We can take $B$ bootstraps of the data and train a new model on each
- Then compute a sample variance using each of these models on this prediction point:
$$
\hat{\mathrm{Var}} = \frac{1}{B-1} \sum_{b=1}^{B} (m_b(z_0) - \hat{m}_{z_0})^2 \\
\hat{m}_{z_0} = \frac{1}{B}\sum_{b=1}^{B} m_b(z_0) 
$$

Can think of this as a [Monte Carlo Estimator of the variance](202101091835_monteCarloEstimator).


Links: 

References: 

